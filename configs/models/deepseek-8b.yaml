# DeepSeek R1 Distill Llama 8B configuration

model:
  # Model identifier
  name: "deepseek-ai/DeepSeek-R1-Distill-Llama-8B"
  display_name: "DeepSeek R1 8B"
  type: "causal"
  
  # Model-specific paths
  pretrained_path: ${paths.pretrained}/deepseek-r1-8b
  
  # Model-specific configurations
  trust_remote_code: true
  use_auth_token: ${oc.env:HF_TOKEN}
  revision: "main"
  torch_dtype: "float32"
  
  model_kwargs:
    device_map: "auto"
    load_in_4bit: true
    max_memory:
      0: "24GiB"  # Adjust based on your GPU memory
    torch_dtype: "float32"
  
  # Generation configurations
  generation:
    max_new_tokens: 1024
    temperature: 0.7
    top_p: 0.9
    repetition_penalty: 1.1
    do_sample: true
